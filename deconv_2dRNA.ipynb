{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants & Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "BULK_PATH = \"input/2dRNA/group1/bulk_RawCounts.tsv\"\n",
    "SC_DIR_PATH = \"input/2dRNA/group1/\"\n",
    "TEST_SIZE = 0.2  # For train-test split\n",
    "EPOCHS = 70  # Number of epochs for training\n",
    "BATCH_SIZE = 32  # Batch size for training\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "np.set_printoptions(linewidth=120)\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading\n",
    "Load necessary files to DataFrames, see info/stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B Matrix (Tissue GEPs) Sample:\n",
      "\n",
      "             gene_id  gene_symbol  CANUCK1057-BAL-LB3B  CANUCK1047-BAL-LB5  RESP1024-BAL-LB5  CANUCK1060-BAL-RB4\n",
      "0  ENSG00000290825.1      DDX11L2                    2                   0                 0                   1\n",
      "1  ENSG00000223972.6      DDX11L1                    0                   0                 0                   0\n",
      "2  ENSG00000227232.6       WASH7P                   89                  81                47                 101\n",
      "3  ENSG00000278267.1    MIR6859-1                   23                  12                 7                  14\n",
      "4  ENSG00000243485.5  MIR1302-2HG                    0                   0                 0                   0\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "B DIMENSIONS: rows (genes) = 63187, columns (patients) = 34\n"
     ]
    }
   ],
   "source": [
    "bulk_df = pd.read_csv(BULK_PATH, sep=\"\\t\")\n",
    "\n",
    "print(\"B Matrix (Tissue GEPs) Sample:\\n\")\n",
    "print(bulk_df.iloc[:, :6].head(5))\n",
    "print(\"\\n----------------------------------------------\")\n",
    "print(f\"\\nB DIMENSIONS: rows (genes) = {bulk_df.shape[0]}, columns (patients) = {bulk_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S Matrix (Cell GEPs) Sample:\n",
      "\n",
      "                cell_id patient_id  TUBA1A  SPA17  ACTG1  TSTD1  H1-0  NQO1  ATP5IF1  DNPH1  NEDD9  ALDH1A1\n",
      "0  AAACCCACAATACGAA-1_1   BAL-RB-2       0      0      1      1     0     0        0      0      0        0\n",
      "1  AAACGAACACGCTATA-1_1   BAL-RB-2      81      1     64      2     0     1        6      1      0       15\n",
      "2  AACAACCCAAACTCGT-1_1   BAL-RB-2       4      0    106      0     0     0        4      1      0       13\n",
      "3  AACACACCAAATTGGA-1_1   BAL-RB-2       0      0      1      0     0     0        0      0      0        0\n",
      "4  AACAGGGGTCGTACTA-1_1   BAL-RB-2       0      0     16      0     0     0        1      0      2        0\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "S DIMENSIONS: rows (patients x cells) = 241924, columns (genes) = 1013\n"
     ]
    }
   ],
   "source": [
    "sc_path = SC_DIR_PATH + \"scRNA_CT1_top200_RawCounts.tsv\"\n",
    "sc_df = pd.read_csv(sc_path, sep=\"\\t\")\n",
    "\n",
    "print(\"S Matrix (Cell GEPs) Sample:\\n\")\n",
    "print(sc_df.iloc[:, :12].head(5))\n",
    "print(\"\\n----------------------------------------------\")\n",
    "print(f\"\\nS DIMENSIONS: rows (patients x cells) = {sc_df.shape[0]}, columns (genes) = {sc_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S Metadata Matrix Sample:\n",
      "\n",
      "                cell_id patient_id  patient_age patient_sex  cell_type_1                cell_type_2                cell_type_3          cell_type_4                      data_source deconv_cluster\n",
      "0  AAACCCACAATACGAA-1_1   BAL-RB-2           32      Female   Epithelial                        NaN                 Epithelial           Epithelial  Post-covid respiratory symptoms     Epithelial\n",
      "1  AAACGAACACGCTATA-1_1   BAL-RB-2           32      Female  Macrophages  Alveolar_Macrophage_CSF1R  Alveolar_Macrophage_CSF1R  Alveolar_macrophage  Post-covid respiratory symptoms    Macrophages\n",
      "2  AACAACCCAAACTCGT-1_1   BAL-RB-2           32      Female  Macrophages           Macrophage_CCL18           Macrophage_CCL18  Alveolar_macrophage  Post-covid respiratory symptoms    Macrophages\n",
      "3  AACACACCAAATTGGA-1_1   BAL-RB-2           32      Female  Macrophages           Macrophage_CCL18           Macrophage_CCL18  Alveolar_macrophage  Post-covid respiratory symptoms    Macrophages\n",
      "4  AACAGGGGTCGTACTA-1_1   BAL-RB-2           32      Female    CD4_Tcell                        NaN                  CD4_Tcell            CD4_Tcell  Post-covid respiratory symptoms      CD4_Tcell\n",
      "\n",
      "----------------------------------------------\n",
      "S Metadata Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 241924 entries, 0 to 241923\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   cell_id         241924 non-null  object\n",
      " 1   patient_id      241924 non-null  object\n",
      " 2   patient_age     241924 non-null  int64 \n",
      " 3   patient_sex     235944 non-null  object\n",
      " 4   cell_type_1     241924 non-null  object\n",
      " 5   cell_type_2     209552 non-null  object\n",
      " 6   cell_type_3     241924 non-null  object\n",
      " 7   cell_type_4     241924 non-null  object\n",
      " 8   data_source     241924 non-null  object\n",
      " 9   deconv_cluster  241924 non-null  object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 18.5+ MB\n",
      "----------------------------------------------\n",
      "\n",
      "S METADATA DIMENSIONS: rows (patients x cells) = 241924, columns (metadata) = 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc_metadata_path = SC_DIR_PATH + \"scRNA_CT1_top200_Metadata.tsv\"\n",
    "sc_metadata_df = pd.read_csv(sc_metadata_path, sep=\"\\t\")\n",
    "\n",
    "print(\"S Metadata Matrix Sample:\\n\")\n",
    "print(sc_metadata_df.head(5))\n",
    "print(\"\\n----------------------------------------------\")\n",
    "print(\"S Metadata Info:\\n\")\n",
    "sc_metadata_df.info()\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"\\nS METADATA DIMENSIONS: rows (patients x cells) = {sc_metadata_df.shape[0]}, columns (metadata) = {sc_metadata_df.shape[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Processing\n",
    "Process bulk and single-cell data to generate training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common genes: 1009\n",
      "(1009, 32)\n",
      "B shape (samples x genes): (32, 1009)\n",
      "C shape (samples x CTs): (32, 11)\n"
     ]
    }
   ],
   "source": [
    "bulk_df_vals = bulk_df.iloc[:, 2:]  # drop gene_id and gene_symbol\n",
    "\n",
    "# Filter B and S to keep only common genes\n",
    "bulk_genes = bulk_df[\"gene_symbol\"].str.strip().str.lower()\n",
    "sc_genes = sc_df.columns[2:].str.strip().str.lower()\n",
    "common_genes = np.intersect1d(bulk_genes, sc_genes)\n",
    "print(\"Common genes:\", len(common_genes))\n",
    "bulk_df_vals = bulk_df_vals.loc[bulk_df[\"gene_symbol\"].isin(common_genes)]\n",
    "print(bulk_df_vals.shape)\n",
    "\n",
    "# Match patient IDs in metadata to bulk matrix column names\n",
    "sc_patient_ids = sc_metadata_df['patient_id'].unique()\n",
    "bulk_patient_ids = bulk_df_vals.columns\n",
    "if not all(pat in bulk_patient_ids for pat in sc_patient_ids):\n",
    "    raise ValueError(\"Patient IDs in S do not match B. Check mapping.\")\n",
    "\n",
    "# Calculate cell-type fractions for each patient\n",
    "ct_labels = sc_metadata_df[\"cell_type_1\"].dropna().unique()\n",
    "C = []\n",
    "for pat in bulk_patient_ids:\n",
    "    cells = sc_metadata_df[sc_metadata_df[\"patient_id\"] == pat]\n",
    "    # TODO: Augmentation -- random sample cells if needed\n",
    "\n",
    "    ct_fractions = cells[\"cell_type_1\"].value_counts(normalize=True)\n",
    "    all_ct_fractions = {ct: ct_fractions.get(ct, 0.0) for ct in ct_labels}  # Impute missing cell types\n",
    "    C.append(list(all_ct_fractions.values()))\n",
    "\n",
    "# Log-normalize bulk data and prepare output arrays\n",
    "B = np.log1p(bulk_df_vals.values.T)  # Transpose to patients x genes numpy array\n",
    "C = np.array(C)\n",
    "\n",
    "print(f\"B shape (samples x genes): {B.shape}\")\n",
    "print(f\"C shape (samples x CTs): {C.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B Sample --------------------------------------------------\n",
      "\n",
      "[[6.1924 3.1355 3.1781 4.4998 3.2581 6.5294 5.4467 7.6353 8.2633 5.0814 4.2195 4.2905 8.8323 6.2785 6.9508]\n",
      " [6.7754 2.4849 1.9459 4.7707 3.1355 6.5639 4.8752 7.5919 7.9352 5.8999 3.1781 4.1744 8.9866 6.3368 6.3172]\n",
      " [6.142  1.9459 3.5835 4.4308 5.4161 6.2672 4.3175 7.1562 7.5694 2.7726 2.1972 3.7842 8.2636 6.5468 6.7154]\n",
      " [7.7165 3.2581 4.654  4.4427 6.1092 5.7777 4.9698 7.4616 7.6246 4.4067 2.0794 4.0604 9.2519 5.9738 6.2804]\n",
      " [7.0166 1.7918 2.0794 5.0304 4.9972 6.3439 4.8363 7.4679 7.5761 5.6419 3.3673 4.6821 8.7358 6.0014 6.286 ]]\n",
      "\n",
      "C Sample --------------------------------------------------\n",
      "\n",
      "[[0.0706 0.8308 0.0156 0.0282 0.0074 0.006  0.0018 0.0075 0.0049 0.0002 0.027 ]\n",
      " [0.0004 0.9668 0.0232 0.0075 0.0002 0.0009 0.0005 0.0003 0.0001 0.     0.    ]\n",
      " [0.0012 0.8548 0.0887 0.0393 0.0004 0.0043 0.0038 0.0069 0.0004 0.0002 0.0001]\n",
      " [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.0012 0.8478 0.1174 0.0193 0.0029 0.005  0.0011 0.0047 0.0003 0.0003 0.    ]\n",
      " [0.0018 0.8365 0.101  0.0473 0.0011 0.0023 0.0045 0.0046 0.0008 0.0001 0.    ]\n",
      " [0.0135 0.819  0.1116 0.0264 0.0018 0.0247 0.0006 0.     0.0024 0.     0.    ]\n",
      " [0.0019 0.8322 0.1098 0.0402 0.0005 0.0056 0.0044 0.0021 0.0032 0.0002 0.    ]\n",
      " [0.0292 0.7037 0.0797 0.0258 0.0011 0.0057 0.0103 0.008  0.     0.0034 0.133 ]\n",
      " [0.0376 0.685  0.2225 0.026  0.0029 0.0058 0.0029 0.0173 0.     0.     0.    ]\n",
      " [0.0018 0.8948 0.0711 0.0198 0.0015 0.0057 0.0027 0.0012 0.0004 0.0011 0.    ]\n",
      " [0.0068 0.9379 0.0383 0.0129 0.0002 0.0025 0.0003 0.0006 0.0006 0.     0.    ]\n",
      " [0.0075 0.8502 0.1055 0.0302 0.0012 0.0036 0.001  0.0002 0.0005 0.0002 0.    ]\n",
      " [0.0011 0.9153 0.0578 0.0144 0.0006 0.0034 0.0038 0.0016 0.0004 0.0003 0.0012]\n",
      " [0.009  0.9371 0.0413 0.0094 0.     0.0016 0.0009 0.0003 0.0003 0.     0.0001]\n",
      " [0.01   0.4508 0.401  0.1087 0.     0.0112 0.0056 0.0112 0.0004 0.     0.0012]\n",
      " [0.0033 0.9519 0.0342 0.0054 0.     0.0037 0.0004 0.0009 0.     0.     0.0002]\n",
      " [0.1369 0.5375 0.1507 0.118  0.0028 0.006  0.0021 0.0078 0.0018 0.0011 0.0352]\n",
      " [0.0035 0.6964 0.2426 0.0423 0.0007 0.0057 0.0028 0.0036 0.0007 0.0008 0.0009]\n",
      " [0.0031 0.8505 0.1027 0.0316 0.0011 0.0031 0.0046 0.001  0.0006 0.0001 0.0016]\n",
      " [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.0545 0.8832 0.0421 0.0074 0.0022 0.0055 0.0015 0.0022 0.001  0.0002 0.0002]\n",
      " [0.0018 0.7554 0.1535 0.0263 0.0167 0.0149 0.0122 0.0167 0.0005 0.0013 0.0007]\n",
      " [0.0654 0.8065 0.0909 0.0234 0.0031 0.0062 0.0004 0.0024 0.0014 0.     0.0004]\n",
      " [0.0058 0.4879 0.3638 0.121  0.0027 0.0066 0.0046 0.0062 0.     0.0015 0.    ]\n",
      " [0.0093 0.701  0.1669 0.1101 0.0006 0.0032 0.0032 0.0047 0.0009 0.     0.    ]\n",
      " [0.0046 0.9911 0.0009 0.0003 0.0001 0.0021 0.0003 0.     0.0002 0.0001 0.0002]\n",
      " [0.0023 0.7956 0.1511 0.0359 0.0023 0.0069 0.     0.0046 0.0012 0.     0.    ]\n",
      " [0.     0.6885 0.235  0.0562 0.0023 0.007  0.0008 0.0078 0.     0.     0.0023]\n",
      " [0.0123 0.8797 0.0634 0.0395 0.0003 0.0017 0.0003 0.0017 0.001  0.     0.    ]\n",
      " [0.0023 0.9144 0.0682 0.0103 0.0013 0.0015 0.0004 0.0009 0.0006 0.     0.    ]\n",
      " [0.0038 0.7196 0.2093 0.0444 0.0036 0.0036 0.0056 0.0099 0.0003 0.     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"B Sample --------------------------------------------------\\n\")\n",
    "print(B[:5, :15])\n",
    "print(\"\\nC Sample --------------------------------------------------\\n\")\n",
    "print(C[:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Training\n",
    "Define model architecture/parameters, run training, eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2dRNA(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Model2dRNA, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(500),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(500, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(100, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "def train_model(model: Model2dRNA, train_set: TensorDataset, test_set: TensorDataset):\n",
    "    model.to(DEVICE)\n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in test_loader:\n",
    "                X_val, y_val = X_val.to(DEVICE), y_val.to(DEVICE)\n",
    "                val_outputs = model(X_val)\n",
    "                val_loss += criterion(val_outputs, y_val).item()\n",
    "        print(f\"Epoch {e+1}/{EPOCHS}, Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "def save_model(model: Model2dRNA, X_test, Y_test):\n",
    "    os.makedirs(\"output\", exist_ok=True)\n",
    "    dtnum = str(datetime.datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
    "    model_dir = os.path.join(\"output\", \"2dRNA\", dtnum)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    model_path = os.path.join(model_dir, \"model.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Saved model to {model_path}\")\n",
    "\n",
    "    # Save predictions and true fractions\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    Y_test = torch.tensor(Y_test, dtype=torch.float32)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test.to(DEVICE)).cpu().numpy()\n",
    "    preds_file = os.path.join(model_dir, \"pred_fractions.csv\")\n",
    "    true_fractions_file = os.path.join(model_dir, \"true_fractions.csv\")\n",
    "    np.savetxt(preds_file, predictions, delimiter=\",\")\n",
    "    np.savetxt(true_fractions_file, Y_test.numpy(), delimiter=\",\")\n",
    "    print(f\"Saved predictions to {preds_file}\")\n",
    "    print(f\"Saved true fractions to {true_fractions_file}\")\n",
    "\n",
    "\n",
    "def eval_model(model: Model2dRNA, X_test, Y_test):\n",
    "    print(\"\\nEvaluating model on Y_test:\")\n",
    "    X_test, Y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(\n",
    "        Y_test, dtype=torch.float32\n",
    "    )\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Y_pred = model(X_test.to(DEVICE)).cpu()\n",
    "\n",
    "    mae = torch.mean(torch.abs(Y_pred - Y_test)).item()\n",
    "    rmse = torch.sqrt(torch.mean((Y_pred - Y_test) ** 2)).item()\n",
    "    cosine = torch.nn.functional.cosine_similarity(Y_pred, Y_test, dim=1).mean().item()\n",
    "\n",
    "    print(f\" - MAE: {mae:.4f}\")\n",
    "    print(f\" - RMSE: {rmse:.4f}\")\n",
    "    print(f\" - Cosine similarity: {cosine:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/70, Loss: 0.3079, Val Loss: 0.1534\n",
      "Epoch 2/70, Loss: 0.3773, Val Loss: 0.2992\n",
      "Epoch 3/70, Loss: 0.2603, Val Loss: 0.4656\n",
      "Epoch 4/70, Loss: 0.2226, Val Loss: 0.7044\n",
      "Epoch 5/70, Loss: 0.1796, Val Loss: 0.8775\n",
      "Epoch 6/70, Loss: 0.1687, Val Loss: 0.9517\n",
      "Epoch 7/70, Loss: 0.1493, Val Loss: 0.9320\n",
      "Epoch 8/70, Loss: 0.1376, Val Loss: 0.8972\n",
      "Epoch 9/70, Loss: 0.1458, Val Loss: 0.7797\n",
      "Epoch 10/70, Loss: 0.1433, Val Loss: 0.7932\n",
      "Epoch 11/70, Loss: 0.1221, Val Loss: 0.9853\n",
      "Epoch 12/70, Loss: 0.1139, Val Loss: 1.3089\n",
      "Epoch 13/70, Loss: 0.1120, Val Loss: 1.7122\n",
      "Epoch 14/70, Loss: 0.0918, Val Loss: 2.0060\n",
      "Epoch 15/70, Loss: 0.0891, Val Loss: 2.3487\n",
      "Epoch 16/70, Loss: 0.0928, Val Loss: 2.4744\n",
      "Epoch 17/70, Loss: 0.0890, Val Loss: 2.5432\n",
      "Epoch 18/70, Loss: 0.0833, Val Loss: 2.6263\n",
      "Epoch 19/70, Loss: 0.0790, Val Loss: 2.5060\n",
      "Epoch 20/70, Loss: 0.0802, Val Loss: 2.2373\n",
      "Epoch 21/70, Loss: 0.0774, Val Loss: 1.9570\n",
      "Epoch 22/70, Loss: 0.0689, Val Loss: 1.7752\n",
      "Epoch 23/70, Loss: 0.0654, Val Loss: 1.5939\n",
      "Epoch 24/70, Loss: 0.0627, Val Loss: 1.3856\n",
      "Epoch 25/70, Loss: 0.0625, Val Loss: 1.1400\n",
      "Epoch 26/70, Loss: 0.0656, Val Loss: 0.9912\n",
      "Epoch 27/70, Loss: 0.0518, Val Loss: 0.8483\n",
      "Epoch 28/70, Loss: 0.0538, Val Loss: 0.7268\n",
      "Epoch 29/70, Loss: 0.0581, Val Loss: 0.6495\n",
      "Epoch 30/70, Loss: 0.0590, Val Loss: 0.5568\n",
      "Epoch 31/70, Loss: 0.0526, Val Loss: 0.5018\n",
      "Epoch 32/70, Loss: 0.0497, Val Loss: 0.4469\n",
      "Epoch 33/70, Loss: 0.0521, Val Loss: 0.4172\n",
      "Epoch 34/70, Loss: 0.0468, Val Loss: 0.3582\n",
      "Epoch 35/70, Loss: 0.0456, Val Loss: 0.3180\n",
      "Epoch 36/70, Loss: 0.0468, Val Loss: 0.2824\n",
      "Epoch 37/70, Loss: 0.0424, Val Loss: 0.2408\n",
      "Epoch 38/70, Loss: 0.0439, Val Loss: 0.2077\n",
      "Epoch 39/70, Loss: 0.0409, Val Loss: 0.1802\n",
      "Epoch 40/70, Loss: 0.0382, Val Loss: 0.1527\n",
      "Epoch 41/70, Loss: 0.0375, Val Loss: 0.1317\n",
      "Epoch 42/70, Loss: 0.0362, Val Loss: 0.1154\n",
      "Epoch 43/70, Loss: 0.0361, Val Loss: 0.0986\n",
      "Epoch 44/70, Loss: 0.0383, Val Loss: 0.0847\n",
      "Epoch 45/70, Loss: 0.0356, Val Loss: 0.0735\n",
      "Epoch 46/70, Loss: 0.0325, Val Loss: 0.0648\n",
      "Epoch 47/70, Loss: 0.0348, Val Loss: 0.0571\n",
      "Epoch 48/70, Loss: 0.0305, Val Loss: 0.0504\n",
      "Epoch 49/70, Loss: 0.0313, Val Loss: 0.0449\n",
      "Epoch 50/70, Loss: 0.0308, Val Loss: 0.0401\n",
      "Epoch 51/70, Loss: 0.0298, Val Loss: 0.0376\n",
      "Epoch 52/70, Loss: 0.0295, Val Loss: 0.0358\n",
      "Epoch 53/70, Loss: 0.0275, Val Loss: 0.0330\n",
      "Epoch 54/70, Loss: 0.0267, Val Loss: 0.0312\n",
      "Epoch 55/70, Loss: 0.0315, Val Loss: 0.0290\n",
      "Epoch 56/70, Loss: 0.0269, Val Loss: 0.0276\n",
      "Epoch 57/70, Loss: 0.0263, Val Loss: 0.0262\n",
      "Epoch 58/70, Loss: 0.0253, Val Loss: 0.0253\n",
      "Epoch 59/70, Loss: 0.0246, Val Loss: 0.0253\n",
      "Epoch 60/70, Loss: 0.0237, Val Loss: 0.0253\n",
      "Epoch 61/70, Loss: 0.0226, Val Loss: 0.0249\n",
      "Epoch 62/70, Loss: 0.0238, Val Loss: 0.0246\n",
      "Epoch 63/70, Loss: 0.0222, Val Loss: 0.0248\n",
      "Epoch 64/70, Loss: 0.0226, Val Loss: 0.0247\n",
      "Epoch 65/70, Loss: 0.0205, Val Loss: 0.0247\n",
      "Epoch 66/70, Loss: 0.0202, Val Loss: 0.0252\n",
      "Epoch 67/70, Loss: 0.0206, Val Loss: 0.0244\n",
      "Epoch 68/70, Loss: 0.0179, Val Loss: 0.0237\n",
      "Epoch 69/70, Loss: 0.0172, Val Loss: 0.0233\n",
      "Epoch 70/70, Loss: 0.0180, Val Loss: 0.0222\n",
      "Training complete!\n",
      "Saved model to output/2dRNA/20241229_1515/model.pth\n",
      "Saved predictions to output/2dRNA/20241229_1515/pred_fractions.csv\n",
      "Saved true fractions to output/2dRNA/20241229_1515/true_fractions.csv\n",
      "\n",
      "Evaluating model on Y_test:\n",
      " - MAE: 0.1002\n",
      " - RMSE: 0.1491\n",
      " - Cosine similarity: 0.7708\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    B, C, test_size=TEST_SIZE, random_state=42\n",
    ")\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32),\n",
    "    torch.tensor(Y_train, dtype=torch.float32),\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32),\n",
    "    torch.tensor(Y_test, dtype=torch.float32),\n",
    ")\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = Y_train.shape[1]\n",
    "model = Model2dRNA(input_dim, output_dim)\n",
    "\n",
    "print(\"Training model...\")\n",
    "train_model(model, train_dataset, test_dataset)\n",
    "print(\"Training complete!\")\n",
    "save_model(model, X_test, Y_test)\n",
    "\n",
    "eval_model(model, X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "based",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
